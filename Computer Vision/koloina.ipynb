{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions\n",
        "\n",
        "Travail individuel à réaliser par chaque étudiant. Chaque fichier devra ensuite être rassemblé par groupe dans le premier dépôt Git de l'année universitaire, dans un nouveau dossier nommé <code>Computer Vision</code>.\n",
        "\n",
        "Le nom du fichier doit être le prénom de l'étudiant écrit en minuscules. Par exemple, si l'étudiant s'appelle BOB Toto, le fichier doit être nommé toto.ipynb."
      ],
      "metadata": {
        "id": "a8E7De68YVps"
      },
      "id": "a8E7De68YVps"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Détails de l'étudiant\n",
        "### Nom(s)  : RAHERIMANANA\n",
        "### Prénom(s) : Andriniaina Koloina Mandresy\n",
        "### Classe : ISAIA 4"
      ],
      "metadata": {
        "id": "K6EHkj63XsUy"
      },
      "id": "K6EHkj63XsUy"
    },
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# Vision par Ordinateur avec Keras/TensorFlow : Un Notebook Pratique et Conceptuel\n",
        "\n",
        "Ce notebook a pour objectif de vous guider pas à pas dans la création et l'analyse d'un modèle de réseau de neurones convolutif (CNN) appliqué au jeu de données CIFAR-10. Chaque étape est accompagnée d'explications pratiques ainsi que de questions conceptuelles pour renforcer votre compréhension des enjeux théoriques et pratiques de la vision par ordinateur."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape1",
      "metadata": {
        "id": "etape1"
      },
      "source": [
        "## Étape 1 : Introduction et Configuration de l'Environnement\n",
        "\n",
        "Dans cette étape, nous allons configurer notre environnement de travail et importer les bibliothèques indispensables pour le deep learning et la manipulation de données. Nous vérifions également la version de TensorFlow pour nous assurer que tout fonctionne correctement.\n",
        "\n",
        "### Explication Pratique\n",
        "La bonne configuration de l'environnement est cruciale pour garantir la reproductibilité et la stabilité de vos expériences. En particulier, les versions des bibliothèques peuvent influencer le comportement du modèle et sa performance, d'où l'importance de vérifier et documenter ces versions dès le début."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code-etape1",
        "outputId": "bb1339f0-25eb-4422-af7b-15b5088ed18a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version de TensorFlow : 2.18.0\n"
          ]
        }
      ],
      "source": [
        "# Importer les bibliothèques nécessaires\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Version de TensorFlow :', tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4tTToDvAOTsa"
      },
      "id": "4tTToDvAOTsa"
    },
    {
      "cell_type": "markdown",
      "id": "question1",
      "metadata": {
        "id": "question1"
      },
      "source": [
        "### Question  1\n",
        "\n",
        "**Q1 :** Pourquoi est-il essentiel de vérifier la configuration de l'environnement (versions des bibliothèques, dépendances, etc.) avant de développer un modèle de deep learning ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REPONSE 1 :**\n",
        "\n",
        "Vérifier la configuration de l’environnement avant de développer un modèle de deep learning est essentiel pour garantir la reproductibilité des résultats, car un même code doit produire des sorties cohérentes, quel que soit l’environnement utilisé. Cela permet également d’assurer la compatibilité des dépendances, car certaines versions de bibliothèques peuvent ne pas fonctionner correctement ensemble, entraînant des erreurs d’exécution. De plus, une bonne configuration contribue à optimiser les performances, en tirant parti des améliorations apportées par les mises à jour en termes de vitesse et d’efficacité mémoire. Enfin, elle permet de prévenir les erreurs et les bugs imprévus qui pourraient survenir à cause d’une incompatibilité ou d’un changement non anticipé dans les versions des outils utilisés."
      ],
      "metadata": {
        "id": "4Nqx3UXbWbjJ"
      },
      "id": "4Nqx3UXbWbjJ"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oZWXUce8OXyu"
      },
      "id": "oZWXUce8OXyu"
    },
    {
      "cell_type": "markdown",
      "id": "etape2",
      "metadata": {
        "id": "etape2"
      },
      "source": [
        "## Étape 2 : Chargement et Prétraitement des Données\n",
        "\n",
        "Nous allons charger le jeu de données CIFAR-10, composé de 60 000 images couleur réparties en 10 classes. Dans cette étape, nous normalisons les valeurs des pixels afin qu'elles soient comprises entre 0 et 1, et nous transformons les étiquettes en format one-hot pour faciliter le processus de classification.\n",
        "\n",
        "### Explication Pratique\n",
        "La normalisation aide à stabiliser et accélérer l'entraînement du modèle en assurant que les valeurs d'entrée ont une échelle comparable. Le one-hot encoding évite que le modèle interprète les étiquettes comme des valeurs numériques ordonnées, ce qui est essentiel pour les problèmes de classification multi-classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape2",
      "metadata": {
        "id": "code-etape2"
      },
      "outputs": [],
      "source": [
        "# Charger le jeu de données CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normaliser les valeurs des pixels (entre 0 et 1)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convertir les vecteurs de classes en matrices binaires (one-hot encoding)\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"Forme des données d'entrainement :\", x_train.shape)\n",
        "print(\"Forme des étiquettes d'entraînement :\", y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question2",
      "metadata": {
        "id": "question2"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "**Q2 :** Expliquez comment la normalisation des pixels et le one-hot encoding des étiquettes contribuent chacun à la stabilité et à l'efficacité de l'entraînement d'un modèle de deep learning.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REPONSE 2 :**\n",
        "\n",
        "Explication de la façon de la normalisation des pixels et le one-hot encoding des étiquettes contibuent chacun à la stabilté et à l'éfficacité de l'entrainement d'un modèle deep learning:\n",
        "\n",
        "\n",
        "\n",
        "*  La normalisation des pixels permet d'éviter des écarts trop importants entre les valeurs d'entrée, cela stabilise l’apprentissage en empêchant certaines valeurs d’avoir une influence disproportionnée et accélère la convergence du modèle en facilitant l’optimisation des poids.\n",
        "\n",
        "*   Le one-hot encoding des étiquettes est essentielle pour éviter que le modèle considère les classes comme des valeurs numériques ordonnées, ce qui pourrait fausser son interprétation des catégories. De plus, dans une classification multi-classes avec une fonction d’activation softmax, ce format optimise le calcul de l’erreur et améliore la capacité du modèle à différencier correctement les classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "inhdV7eqZoWP"
      },
      "id": "inhdV7eqZoWP"
    },
    {
      "cell_type": "markdown",
      "id": "etape3",
      "metadata": {
        "id": "etape3"
      },
      "source": [
        "## Étape 3 : Exploration et Visualisation des Données\n",
        "\n",
        "Avant de construire le modèle, il est important d'explorer et de visualiser les données. Nous affichons ainsi un échantillon d'images du jeu de données pour mieux comprendre leur contenu et la distribution des classes.\n",
        "\n",
        "### Explication Pratique\n",
        "La visualisation des données permet d'identifier d'éventuelles anomalies, comme des classes sous-représentées ou des images bruitées, et de décider si des techniques d'augmentation de données ou de prétraitement supplémentaires sont nécessaires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape3",
      "metadata": {
        "id": "code-etape3"
      },
      "outputs": [],
      "source": [
        "# Afficher quelques images du jeu de données d'entraînement\n",
        "noms_classes = ['avion', 'automobile', 'oiseau', 'chat', 'cerf',\n",
        "               'chien', 'grenouille', 'cheval', 'navire', 'camion']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.xlabel(noms_classes[y_train[i].argmax()])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question3",
      "metadata": {
        "id": "question3"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "**Q3 :** D'après la visualisation, discutez de l'impact potentiel d'une distribution inégale des classes ou de la présence d'images de mauvaise qualité sur la performance d'un modèle de classification. Quelles stratégies pourraient être mises en place pour pallier ces problèmes ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REPONSE 3 :**\n",
        "\n",
        "Discussion:\n",
        "\n",
        "*   Une distribution inégale des classes peut entrainer un déséquilibre du modèle, qui risque de mieux reconnaitre les classes majoritaires au détriment des classes sous-représentées et cela peut fausser les prédictions et réduire la capacité du modèle à généraliser correctement.\n",
        "\n",
        "*   La présence d'image de mauvaise qualité peut introduire du bruit dans l'entrainement, rendant l'apprentissage plus difficile et réduisant la précision du modèle.\n",
        "\n",
        "Les stratégies qui pourraient être mises en place:\n",
        "\n",
        "*   Techniques d'augmentation de données c'est à dire génération d nouvelles images en appliquant des transformation pour équilibrer les classes et enrichir\n",
        "\n",
        "*   Sous-échantillonnage et sur-échantillonnage c'est à dire réduction du nombre d'image des classes majoritaires ou augmenter celui des classes minoritaires pour obtenir une distribution plus équilibrée.\n",
        "\n",
        "*   Nettoyage des données c'est-à-dire supprimer ou corriger les images de mauvaises qualité afin d'améliorer la cohérence du jeu de données.\n",
        "\n",
        "*   Utilisation de pondéation de classe c'est-à-dire attribuer un poids plus élevé aux classes sous-représentées dans la fonction de perte pour équilibrer leur influence lors de l'apprentissage.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KioBzVq8eDdc"
      },
      "id": "KioBzVq8eDdc"
    },
    {
      "cell_type": "markdown",
      "id": "etape4",
      "metadata": {
        "id": "etape4"
      },
      "source": [
        "## Étape 4 : Construction du Modèle CNN\n",
        "\n",
        "Nous allons construire un réseau de neurones convolutif (CNN) pour extraire des caractéristiques hiérarchiques des images. Ce modèle se compose de plusieurs blocs de convolution suivis de couches de pooling et se termine par des couches entièrement connectées pour la classification.\n",
        "\n",
        "### Explication Pratique\n",
        "Les couches de convolution permettent au modèle de détecter des motifs locaux (comme les contours ou les textures), tandis que les couches de pooling réduisent la dimensionnalité, ce qui diminue la charge computationnelle et aide à rendre le modèle plus robuste aux translations. Le dropout, quant à lui, est une technique de régularisation qui aide à prévenir le surapprentissage en désactivant aléatoirement certains neurones pendant l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape4",
      "metadata": {
        "id": "code-etape4"
      },
      "outputs": [],
      "source": [
        "# Construire le modèle CNN\n",
        "model = models.Sequential()\n",
        "\n",
        "# Bloc de convolution 1 : 32 filtres, taille 3x3, activation ReLU\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Bloc de convolution 2 : 64 filtres\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Bloc de convolution 3 : 64 filtres\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Aplatir les sorties et ajouter des couches entièrement connectées\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question4",
      "metadata": {
        "id": "question4"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "**Q4 :** Décrivez le rôle de chaque composant du CNN (couches de convolution, pooling et dropout) et expliquez comment ils interagissent pour permettre au modèle d'extraire des caractéristiques pertinentes des images.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REPONSE 4 :**\n",
        "\n",
        "Déscription du rôle de chaque composant du CNN:\n",
        "\n",
        "*   Les **couches de convolution** applique des filtres qui parcourent l'image et détectent des motifs locaux comme les contours, les textures ou les formes. Chaque filtre apprend une caractéristique spécifique, et en empilant plusieurs couches de convolutions,  le modèle peut capter des informations de plus en plus complexes à différents niveaux d’abstraction.\n",
        "\n",
        "*   Les **couches pooling**  réduisent la dimensionnalité des données en conservant uniquement les valeurs maximales dans une région donnée. Cela permet de diminuer le nombre de paramètres du modèle, rendant l’entraînement plus rapide et le modèle plus robuste aux petites variations, comme des translations ou des déformations dans les images\n",
        "\n",
        "*   La **couche Dropout** est une téchnique de régularisation qui désactive aléatoirement un certain pourcentage de neurones à chaque itération de l'entrainement, cela empêche le modèle de trop dépendre de certains neurones et réduit ainsi le risque de surapprentissage, améliorant la généralisation aux nouvelles données.\n",
        "\n",
        "*   La **couche Flatten** transforme les matrices obtenues après les couches de convolution et de pooling en un vecteur unidimensionnel pour permettre l’entrée dans les couches entièrement connectées. Ces couches prennent les caractéristiques extraites et les utilisent pour effectuer la classification en associant des probabilités aux différentes classes.\n",
        "\n",
        "*    La **couche de sortie** utilise une activation softmax pour convertir les valeurs en probabilités normalisées, permettant ainsi au modèle de prédire à quelle classe appartient chaque image.\n",
        "\n",
        "\n",
        " Et en combinant ces composants, le CNN apprend progressivement à détecter les motifs essentiels des images, tout en optimisant ses performances pour la classification avec robustesse et efficacité."
      ],
      "metadata": {
        "id": "M22kjLbziwSs"
      },
      "id": "M22kjLbziwSs"
    },
    {
      "cell_type": "markdown",
      "id": "etape5",
      "metadata": {
        "id": "etape5"
      },
      "source": [
        "## Étape 5 : Compilation et Entraînement du Modèle\n",
        "\n",
        "Nous allons maintenant compiler le modèle en choisissant un optimiseur, une fonction de perte ainsi que des métriques d'évaluation. Ensuite, nous entraînons le modèle sur les données d'entraînement en réservant une partie des données pour la validation.\n",
        "\n",
        "### Explication Pratique\n",
        "La compilation configure le processus d'apprentissage, notamment la manière dont les poids seront ajustés via la rétropropagation. Le choix de l'optimiseur (ici, Adam) et la définition des hyperparamètres (comme le taux d'apprentissage et la taille du batch) influencent grandement la vitesse de convergence et la qualité finale du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape5",
      "metadata": {
        "id": "code-etape5"
      },
      "outputs": [],
      "source": [
        "# Compiler le modèle\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entraîner le modèle\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question5",
      "metadata": {
        "id": "question5"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "**Q5 :** Quels sont les effets d'un choix inadapté d'hyperparamètres (comme le taux d'apprentissage ou la taille du batch) sur l'entraînement d'un réseau de neurones ? Expliquez en quoi un optimiseur bien configuré est crucial pour la convergence du modèle.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REPONSE 5 :**\n",
        "Les effets d'un choix inadapté d'hyperparamètre sur l' entrainement d'un réseau de neurones sont :\n",
        "*   Taux d'apprentissage trop élevé\n",
        "*   Taux trop faible\n",
        "*   Batch trop petit\n",
        "*   Batch tro grand\n",
        "\n",
        "Un optimiseur bien configuré est crucial pour la convergence du modèle car il ajuste dynamiquement le taux d'appretissage, accélère la convergence et améliore la stabilité de l'entrainement.\n"
      ],
      "metadata": {
        "id": "WgZkjrP8n9PE"
      },
      "id": "WgZkjrP8n9PE"
    },
    {
      "cell_type": "markdown",
      "id": "etape6",
      "metadata": {
        "id": "etape6"
      },
      "source": [
        "## Étape 6 : Évaluation du Modèle\n",
        "\n",
        "Après l'entraînement, nous évaluons notre modèle sur le jeu de test afin de mesurer sa capacité de généralisation sur des données inédites. Les métriques telles que la perte et la précision nous aident à quantifier la performance globale du modèle.\n",
        "\n",
        "### Explication Pratique\n",
        "L'évaluation sur un jeu de test indépendant permet de détecter un éventuel surapprentissage (overfitting). Si le modèle présente une bonne performance sur l'entraînement mais une performance médiocre sur le test, cela indique qu'il n'a pas suffisamment généralisé, ce qui peut nécessiter des ajustements comme plus de régularisation ou des techniques d'augmentation de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape6",
      "metadata": {
        "id": "code-etape6"
      },
      "outputs": [],
      "source": [
        "# Évaluer le modèle sur le jeu de test\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Précision sur le jeu de test :', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question6",
      "metadata": {
        "id": "question6"
      },
      "source": [
        "### Question  6\n",
        "\n",
        "**Q6 :** Que nous indiquent la perte et la précision obtenues lors de l'évaluation sur le jeu de test ? Quels ajustements pourriez-vous envisager si vous observez un écart significatif entre les performances sur l'entraînement et le test ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REPONSE 6 :**\n",
        "\n",
        "La perte et la précision obtenues lors de l'évaluation sur le jeu de test indique la capacité du modèle à généraliser sur des données qu'il n'a pas vues pendant l'entrainement.\n",
        "\n",
        "Les Ajustements qu'on peut envisager si on obsèrve un écrat significatif entre les performances sur l'entrainement et le test sont :\n",
        "\n",
        "*   Augmentation de la régularisation.\n",
        "\n",
        "*   Utilisation des techniques d'augmentation de données.\n",
        "\n",
        "*   Réduction de la compléxité du modèle.\n",
        "\n",
        "*   Améliorer le taux d'apprentissage ou les autres hyperparamètre.\n",
        "\n"
      ],
      "metadata": {
        "id": "lynsPPkgpbpy"
      },
      "id": "lynsPPkgpbpy"
    },
    {
      "cell_type": "markdown",
      "id": "etape7",
      "metadata": {
        "id": "etape7"
      },
      "source": [
        "## Étape 7 : Prédictions et Visualisation des Résultats\n",
        "\n",
        "Nous allons utiliser le modèle entraîné pour prédire les classes des images du jeu de test. La visualisation des résultats nous permet de comparer les étiquettes prédites aux étiquettes réelles et d'identifier les erreurs potentielles.\n",
        "\n",
        "### Explication Pratique\n",
        "La visualisation aide à comprendre qualitativement comment le modèle se comporte face à différentes images. Cela permet d'identifier si certaines classes sont systématiquement mal prédites ou si le modèle confond certaines catégories, ouvrant ainsi la voie à des améliorations ultérieures (par exemple, via l'augmentation de données ou des ajustements de l'architecture)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape7",
      "metadata": {
        "id": "code-etape7"
      },
      "outputs": [],
      "source": [
        "# Faire des prédictions sur le jeu de test\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Fonction pour afficher l'image avec les étiquettes prédites et réelles\n",
        "def afficher_image(i, predictions_array, etiquette_vraie, img):\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    etiquette_predite = np.argmax(predictions_array)\n",
        "    etiquette_vraie = np.argmax(etiquette_vraie)\n",
        "\n",
        "    couleur = 'blue' if etiquette_predite == etiquette_vraie else 'red'\n",
        "    plt.xlabel(f\"Prédit : {noms_classes[etiquette_predite]} (Vrai : {noms_classes[etiquette_vraie]})\", color=couleur)\n",
        "\n",
        "# Afficher quelques images de test avec leurs prédictions\n",
        "nb_lignes = 5\n",
        "nb_colonnes = 3\n",
        "nb_images = nb_lignes * nb_colonnes\n",
        "plt.figure(figsize=(2 * nb_colonnes, 2 * nb_lignes))\n",
        "for i in range(nb_images):\n",
        "    plt.subplot(nb_lignes, nb_colonnes, i+1)\n",
        "    afficher_image(i, predictions[i], y_test[i], x_test[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question7",
      "metadata": {
        "id": "question7"
      },
      "source": [
        "### Question 7\n",
        "\n",
        "**Q7 :** Après avoir examiné les prédictions, identifiez et discutez des stratégies conceptuelles (par exemple, l'augmentation de données, le raffinement de l'architecture ou l'ajustement des hyperparamètres) qui pourraient améliorer la robustesse et la précision du modèle.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REPONSE 7 :**\n",
        "\n",
        "Identification et discussion des stratégies conceptuelle :\n",
        "\n",
        "*  **Augmentation des données** :  en modifiant les images on génère plus de données d'entraînement, ce qui permet au modèle d'apprendre à partir de plus de variations et de mieux généraliser.\n",
        "\n",
        "*   **Raffinement de l'architecture** : Ajouter des couches de convolution ou utiliser des architectures pré-entraînées  aide à capter des motifs complexes dans les images, améliorant ainsi la précision du modèle.\n",
        "\n",
        "*   **Ajustement des hyperparamètres** : Modifier des paramètres comme le taux d'apprentissage ou la taille du batch peut accélérer ou ralentir l'apprentissage. Bien ajustés, ils permettent au modèle de mieux converger et d'apprendre plus efficacement.\n",
        "\n",
        "*   **Utilisation de régularisation** : Des techniques comme le Dropout ou la normalisation par lot aident à éviter le surapprentissage en forçant le modèle à ne pas se fier à des caractéristiques spécifiques des données d'entraînement.\n",
        "\n",
        "*   **Rééquilibrage des classes** : Si certaines classes sont moins présentes, cela peut biaiser le modèle. Le rééchantillonnage ou l’ajout de poids aux classes minoritaires aide à corriger ce déséquilibre, améliorant ainsi la précision des prédictions sur ces classes.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_5klY-RWrpr_"
      },
      "id": "_5klY-RWrpr_"
    },
    {
      "cell_type": "markdown",
      "id": "etape8",
      "metadata": {
        "id": "etape8"
      },
      "source": [
        "## Étape 8 : Conclusion et Travaux Futurs\n",
        "\n",
        "Dans ce notebook, nous avons :\n",
        "- Configuré l'environnement et importé les bibliothèques nécessaires\n",
        "- Chargé et prétraité le jeu de données CIFAR-10\n",
        "- Exploré et visualisé les données\n",
        "- Construit, compilé et entraîné un modèle CNN\n",
        "- Évalué le modèle et visualisé ses prédictions\n",
        "\n",
        "### Explication Pratique\n",
        "Ce pipeline offre une approche complète, à la fois pratique et conceptuelle, pour la mise en œuvre d'un modèle de vision par ordinateur. Pour aller plus loin, vous pouvez explorer des architectures plus complexes, appliquer des techniques d'augmentation de données ou encore expérimenter avec différents optimisateurs afin de mieux comprendre l'impact de chacun sur la performance du modèle."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}